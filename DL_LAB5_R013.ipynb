{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course : Deep Learning  \n",
    "Program : MBA Tech AI  \n",
    "Sem : üáª  \n",
    "Academic year : 2024-25  \n",
    "Instructor : Radhika Chaperneri\n",
    "Name : Dhruv Pithadia  \n",
    "Roll No : R013\n",
    "Batch : B1\n",
    "Date : 29-08-2024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras._tf_keras.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mlp = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "Y_train_mlp = Y_train\n",
    "\n",
    "X_test_mlp = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "Y_test_mlp = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28) Y_train shape (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape, \"Y_train shape\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x332432600>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2\n",
    "                        \"Dress\",        # index 3\n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6\n",
    "                        \"Sneaker\",      # index 7\n",
    "                        \"Bag\",          # index 8\n",
    "                        \"Ankle boot\"]   # index 9\n",
    " \n",
    "img_index = 5\n",
    " \n",
    "label_index = Y_train[img_index]\n",
    " \n",
    "print (\"Y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    " \n",
    "plt.imshow(X_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_mlp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   0,   0,  13,  73,   0,   0,   1,\n",
       "         4,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   3,   0,  36, 136, 127,  62,\n",
       "        54,   0,   0,   0,   1,   3,   4,   0,   0,   3,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0, 102, 204,\n",
       "       176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,\n",
       "        15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         0,  69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,\n",
       "        88, 172,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         1,   1,   0, 200, 232, 232, 233, 229, 223, 223, 215, 213, 164,\n",
       "       127, 123, 196, 229,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 183, 225, 216, 223, 228, 235, 227, 224,\n",
       "       222, 224, 221, 223, 245, 173,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 193, 228, 218, 213, 198, 180,\n",
       "       212, 210, 211, 213, 223, 220, 243, 202,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   3,   0,  12, 219, 220, 212, 218,\n",
       "       192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244, 222,\n",
       "       220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "       236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "        92,   0,   0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,\n",
       "         0, 237, 226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215,\n",
       "       218, 255,  77,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "        62, 145, 204, 228, 207, 213, 221, 218, 208, 211, 218, 224, 223,\n",
       "       219, 215, 224, 244, 159,   0,   0,   0,   0,   0,  18,  44,  82,\n",
       "       107, 189, 228, 220, 222, 217, 226, 200, 205, 211, 230, 224, 234,\n",
       "       176, 188, 250, 248, 233, 238, 215,   0,   0,  57, 187, 208, 224,\n",
       "       221, 224, 208, 204, 214, 208, 209, 200, 159, 245, 193, 206, 223,\n",
       "       255, 255, 221, 234, 221, 211, 220, 232, 246,   0,   3, 202, 228,\n",
       "       224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80, 150, 255,\n",
       "       229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0,  98,\n",
       "       233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
       "        65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,\n",
       "        29,  75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206,\n",
       "       198, 213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220,\n",
       "       221, 230,  67,  48, 203, 183, 194, 213, 197, 185, 190, 194, 192,\n",
       "       202, 214, 219, 221, 220, 236, 225, 216, 199, 206, 186, 181, 177,\n",
       "       172, 181, 205, 206, 115,   0, 122, 219, 193, 179, 171, 183, 196,\n",
       "       204, 210, 213, 207, 211, 210, 200, 196, 194, 191, 195, 191, 198,\n",
       "       192, 176, 156, 167, 177, 210,  92,   0,   0,  74, 189, 212, 191,\n",
       "       175, 172, 175, 181, 185, 188, 189, 188, 193, 198, 204, 209, 210,\n",
       "       210, 211, 188, 188, 194, 192, 216, 170,   0,   2,   0,   0,   0,\n",
       "        66, 200, 222, 237, 239, 242, 246, 243, 244, 221, 220, 193, 191,\n",
       "       179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mlp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mlp = X_train_mlp.astype('float32')\n",
    "X_test_mlp = X_test_mlp.astype('float32')\n",
    "X_train_mlp /= 255\n",
    "X_test_mlp /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
       "       0.28627452, 0.        , 0.        , 0.00392157, 0.01568628,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.14117648, 0.53333336, 0.49803922, 0.24313726,\n",
       "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01176471, 0.01568628, 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "       0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
       "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.60784316, 0.9254902 , 0.8117647 ,\n",
       "       0.69803923, 0.41960785, 0.6117647 , 0.6313726 , 0.42745098,\n",
       "       0.2509804 , 0.09019608, 0.3019608 , 0.50980395, 0.28235295,\n",
       "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.        , 0.27058825,\n",
       "       0.8117647 , 0.8745098 , 0.85490197, 0.84705883, 0.84705883,\n",
       "       0.6392157 , 0.49803922, 0.4745098 , 0.47843137, 0.57254905,\n",
       "       0.5529412 , 0.34509805, 0.6745098 , 0.25882354, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
       "       0.00392157, 0.        , 0.78431374, 0.9098039 , 0.9098039 ,\n",
       "       0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 , 0.84313726,\n",
       "       0.8352941 , 0.6431373 , 0.49803922, 0.48235294, 0.76862746,\n",
       "       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.7176471 , 0.88235295, 0.84705883, 0.8745098 , 0.89411765,\n",
       "       0.92156863, 0.8901961 , 0.8784314 , 0.87058824, 0.8784314 ,\n",
       "       0.8666667 , 0.8745098 , 0.9607843 , 0.6784314 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
       "       0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
       "       0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
       "       0.9529412 , 0.7921569 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
       "       0.04705882, 0.85882354, 0.8627451 , 0.83137256, 0.85490197,\n",
       "       0.7529412 , 0.6627451 , 0.8901961 , 0.8156863 , 0.85490197,\n",
       "       0.8784314 , 0.83137256, 0.8862745 , 0.77254903, 0.81960785,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02352941, 0.        , 0.3882353 , 0.95686275,\n",
       "       0.87058824, 0.8627451 , 0.85490197, 0.79607844, 0.7764706 ,\n",
       "       0.8666667 , 0.84313726, 0.8352941 , 0.87058824, 0.8627451 ,\n",
       "       0.9607843 , 0.46666667, 0.654902  , 0.21960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568628, 0.        ,\n",
       "       0.        , 0.21568628, 0.9254902 , 0.89411765, 0.9019608 ,\n",
       "       0.89411765, 0.9411765 , 0.9098039 , 0.8352941 , 0.85490197,\n",
       "       0.8745098 , 0.91764706, 0.8509804 , 0.8509804 , 0.81960785,\n",
       "       0.36078432, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01568628, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.92941177,\n",
       "       0.8862745 , 0.8509804 , 0.8745098 , 0.87058824, 0.85882354,\n",
       "       0.87058824, 0.8666667 , 0.84705883, 0.8745098 , 0.8980392 ,\n",
       "       0.84313726, 0.85490197, 1.        , 0.3019608 , 0.        ,\n",
       "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
       "       0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
       "       0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
       "       0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
       "       0.95686275, 0.62352943, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156864,\n",
       "       0.41960785, 0.7411765 , 0.89411765, 0.8627451 , 0.87058824,\n",
       "       0.8509804 , 0.8862745 , 0.78431374, 0.8039216 , 0.827451  ,\n",
       "       0.9019608 , 0.8784314 , 0.91764706, 0.6901961 , 0.7372549 ,\n",
       "       0.98039216, 0.972549  , 0.9137255 , 0.93333334, 0.84313726,\n",
       "       0.        , 0.        , 0.22352941, 0.73333335, 0.8156863 ,\n",
       "       0.8784314 , 0.8666667 , 0.8784314 , 0.8156863 , 0.8       ,\n",
       "       0.8392157 , 0.8156863 , 0.81960785, 0.78431374, 0.62352943,\n",
       "       0.9607843 , 0.75686276, 0.80784315, 0.8745098 , 1.        ,\n",
       "       1.        , 0.8666667 , 0.91764706, 0.8666667 , 0.827451  ,\n",
       "       0.8627451 , 0.9098039 , 0.9647059 , 0.        , 0.01176471,\n",
       "       0.7921569 , 0.89411765, 0.8784314 , 0.8666667 , 0.827451  ,\n",
       "       0.827451  , 0.8392157 , 0.8039216 , 0.8039216 , 0.8039216 ,\n",
       "       0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 , 1.        ,\n",
       "       0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 , 0.7490196 ,\n",
       "       0.8235294 , 0.8       , 0.81960785, 0.87058824, 0.89411765,\n",
       "       0.88235295, 0.        , 0.38431373, 0.9137255 , 0.7764706 ,\n",
       "       0.8235294 , 0.87058824, 0.8980392 , 0.8980392 , 0.91764706,\n",
       "       0.9764706 , 0.8627451 , 0.7607843 , 0.84313726, 0.8509804 ,\n",
       "       0.94509804, 0.25490198, 0.28627452, 0.41568628, 0.45882353,\n",
       "       0.65882355, 0.85882354, 0.8666667 , 0.84313726, 0.8509804 ,\n",
       "       0.8745098 , 0.8745098 , 0.8784314 , 0.8980392 , 0.11372549,\n",
       "       0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
       "       0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
       "       0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
       "       0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
       "       0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
       "       0.8666667 , 0.9019608 , 0.2627451 , 0.1882353 , 0.79607844,\n",
       "       0.7176471 , 0.7607843 , 0.8352941 , 0.77254903, 0.7254902 ,\n",
       "       0.74509805, 0.7607843 , 0.7529412 , 0.7921569 , 0.8392157 ,\n",
       "       0.85882354, 0.8666667 , 0.8627451 , 0.9254902 , 0.88235295,\n",
       "       0.84705883, 0.78039217, 0.80784315, 0.7294118 , 0.70980394,\n",
       "       0.69411767, 0.6745098 , 0.70980394, 0.8039216 , 0.80784315,\n",
       "       0.4509804 , 0.        , 0.47843137, 0.85882354, 0.75686276,\n",
       "       0.7019608 , 0.67058825, 0.7176471 , 0.76862746, 0.8       ,\n",
       "       0.8235294 , 0.8352941 , 0.8117647 , 0.827451  , 0.8235294 ,\n",
       "       0.78431374, 0.76862746, 0.7607843 , 0.7490196 , 0.7647059 ,\n",
       "       0.7490196 , 0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 ,\n",
       "       0.654902  , 0.69411767, 0.8235294 , 0.36078432, 0.        ,\n",
       "       0.        , 0.2901961 , 0.7411765 , 0.83137256, 0.7490196 ,\n",
       "       0.6862745 , 0.6745098 , 0.6862745 , 0.70980394, 0.7254902 ,\n",
       "       0.7372549 , 0.7411765 , 0.7372549 , 0.75686276, 0.7764706 ,\n",
       "       0.8       , 0.81960785, 0.8235294 , 0.8235294 , 0.827451  ,\n",
       "       0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 , 0.84705883,\n",
       "       0.6666667 , 0.        , 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.25882354, 0.78431374, 0.87058824, 0.92941177,\n",
       "       0.9372549 , 0.9490196 , 0.9647059 , 0.9529412 , 0.95686275,\n",
       "       0.8666667 , 0.8627451 , 0.75686276, 0.7490196 , 0.7019608 ,\n",
       "       0.7137255 , 0.7137255 , 0.70980394, 0.6901961 , 0.6509804 ,\n",
       "       0.65882355, 0.3882353 , 0.22745098, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "       0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mlp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_mlp = keras.utils.to_categorical(Y_train_mlp, num_classes)\n",
    "Y_test_mlp = keras.utils.to_categorical(Y_test_mlp, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_mlp[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mlp, X_val_mlp, Y_train_mlp, Y_val_mlp = train_test_split(X_train_mlp, Y_train_mlp, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_mlp.shape)\n",
    "print(X_val_mlp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "#from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">625</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">490,625</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,260</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m625\u001b[0m)            ‚îÇ       \u001b[38;5;34m490,625\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             ‚îÇ         \u001b[38;5;34m6,260\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">496,885</span> (1.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m496,885\u001b[0m (1.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">496,885</span> (1.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m496,885\u001b[0m (1.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_dim = 784, activation='sigmoid', units=625, kernel_initializer='normal'))\n",
    "\n",
    "model.add(Dense(input_dim = 625, activation='softmax', units=10, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.05), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4917 - loss: 1.7314 - val_accuracy: 0.7043 - val_loss: 0.9882\n",
      "Epoch 2/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.9150 - val_accuracy: 0.7490 - val_loss: 0.7757\n",
      "Epoch 3/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.7581 - val_accuracy: 0.7657 - val_loss: 0.6958\n",
      "Epoch 4/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.6842 - val_accuracy: 0.7720 - val_loss: 0.6503\n",
      "Epoch 5/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.6412 - val_accuracy: 0.7862 - val_loss: 0.6166\n",
      "Epoch 6/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.6100 - val_accuracy: 0.7906 - val_loss: 0.5986\n",
      "Epoch 7/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.5834 - val_accuracy: 0.8008 - val_loss: 0.5692\n",
      "Epoch 8/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.5700 - val_accuracy: 0.8037 - val_loss: 0.5568\n",
      "Epoch 9/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5540 - val_accuracy: 0.8081 - val_loss: 0.5445\n",
      "Epoch 10/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.5396 - val_accuracy: 0.8106 - val_loss: 0.5364\n",
      "Epoch 11/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.5332 - val_accuracy: 0.8126 - val_loss: 0.5278\n",
      "Epoch 12/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.5201 - val_accuracy: 0.8198 - val_loss: 0.5116\n",
      "Epoch 13/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.5058 - val_accuracy: 0.8206 - val_loss: 0.5089\n",
      "Epoch 14/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.5062 - val_accuracy: 0.8228 - val_loss: 0.5014\n",
      "Epoch 15/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4983 - val_accuracy: 0.8250 - val_loss: 0.4934\n",
      "Epoch 16/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4936 - val_accuracy: 0.8273 - val_loss: 0.4937\n",
      "Epoch 17/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4888 - val_accuracy: 0.8284 - val_loss: 0.4849\n",
      "Epoch 18/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4812 - val_accuracy: 0.8307 - val_loss: 0.4812\n",
      "Epoch 19/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.4820 - val_accuracy: 0.8327 - val_loss: 0.4740\n",
      "Epoch 20/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.4745 - val_accuracy: 0.8315 - val_loss: 0.4750\n",
      "Epoch 21/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.4705 - val_accuracy: 0.8352 - val_loss: 0.4682\n",
      "Epoch 22/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.4611 - val_accuracy: 0.8353 - val_loss: 0.4683\n",
      "Epoch 23/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.4591 - val_accuracy: 0.8368 - val_loss: 0.4645\n",
      "Epoch 24/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.4606 - val_accuracy: 0.8378 - val_loss: 0.4596\n",
      "Epoch 25/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.4550 - val_accuracy: 0.8387 - val_loss: 0.4577\n",
      "Epoch 26/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4518 - val_accuracy: 0.8408 - val_loss: 0.4542\n",
      "Epoch 27/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.4481 - val_accuracy: 0.8416 - val_loss: 0.4530\n",
      "Epoch 28/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.4517 - val_accuracy: 0.8408 - val_loss: 0.4517\n",
      "Epoch 29/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.4400 - val_accuracy: 0.8418 - val_loss: 0.4504\n",
      "Epoch 30/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.4484 - val_accuracy: 0.8374 - val_loss: 0.4506\n",
      "Epoch 31/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.4413 - val_accuracy: 0.8422 - val_loss: 0.4468\n",
      "Epoch 32/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.4440 - val_accuracy: 0.8406 - val_loss: 0.4482\n",
      "Epoch 33/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.4317 - val_accuracy: 0.8418 - val_loss: 0.4454\n",
      "Epoch 34/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.4388 - val_accuracy: 0.8393 - val_loss: 0.4496\n",
      "Epoch 35/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.4369 - val_accuracy: 0.8445 - val_loss: 0.4392\n",
      "Epoch 36/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8503 - loss: 0.4323 - val_accuracy: 0.8416 - val_loss: 0.4491\n",
      "Epoch 37/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.4281 - val_accuracy: 0.8438 - val_loss: 0.4422\n",
      "Epoch 38/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.4317 - val_accuracy: 0.8452 - val_loss: 0.4389\n",
      "Epoch 39/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.4267 - val_accuracy: 0.8421 - val_loss: 0.4458\n",
      "Epoch 40/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.4213 - val_accuracy: 0.8465 - val_loss: 0.4344\n",
      "Epoch 41/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.4219 - val_accuracy: 0.8481 - val_loss: 0.4300\n",
      "Epoch 42/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.4274 - val_accuracy: 0.8493 - val_loss: 0.4297\n",
      "Epoch 43/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.4252 - val_accuracy: 0.8482 - val_loss: 0.4283\n",
      "Epoch 44/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.4166 - val_accuracy: 0.8420 - val_loss: 0.4424\n",
      "Epoch 45/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.4227 - val_accuracy: 0.8458 - val_loss: 0.4314\n",
      "Epoch 46/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.4133 - val_accuracy: 0.8485 - val_loss: 0.4276\n",
      "Epoch 47/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.4205 - val_accuracy: 0.8465 - val_loss: 0.4296\n",
      "Epoch 48/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.4141 - val_accuracy: 0.8469 - val_loss: 0.4268\n",
      "Epoch 49/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.4097 - val_accuracy: 0.8513 - val_loss: 0.4224\n",
      "Epoch 50/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.4139 - val_accuracy: 0.8497 - val_loss: 0.4258\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_mlp, Y_train_mlp,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val_mlp, Y_val_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8369 - loss: 0.4514\n",
      "\n",
      "MLP Test Loss: 0.45673564076423645\n",
      "MLP Test Accuracy: 0.8345999717712402\n"
     ]
    }
   ],
   "source": [
    "score  = model.evaluate(X_test_mlp, Y_test_mlp, verbose = 1)\n",
    "print()\n",
    "print('MLP Test Loss:' , score[0])\n",
    "print('MLP Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Multi Layer Perceptron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
